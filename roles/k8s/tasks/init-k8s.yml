# https://k21academy.com/docker-kubernetes/container-runtime-is-not-running/
#- name: Delete config.toml
#  file:
#    path: "{{ item }}"
#    state: absent
#  register: config_toml_deleted
#  with_items:
#    - "/etc/containerd/config.toml"
#  when: ansible_distribution == "openSUSE Leap"
#- debug: msg={{ config_toml_deleted }}
#  when: print_debug and ansible_distribution == "openSUSE Leap"


#- name: Restart Containerd to Apply Changes in config.toml
#  systemd:
#    name: containerd
#    state: restarted
#  register: containerd_restarted
#  until: containerd_restarted is succeeded
#  retries: 20
#  delay: 10
#  when: ansible_distribution == "openSUSE Leap"


- name: Reset Kubernetes
  command: kubeadm reset -f
  when: inventory_hostname in groups['master']


- name: Config image pull
  command: kubeadm config images pull
  when: inventory_hostname in groups['master']


- name: Initialize Kubernetest Master and Create Cluster
  shell: |
    kubeadm init --apiserver-advertise-address={{ hostvars[groups['master'][0]]['ansible_'~netdev1]['ipv4']['address'] }} \
    --pod-network-cidr=10.142.0.0/16 --cri-socket=unix:///run/containerd/containerd.sock --ignore-preflight-errors=all
  async: 360
  poll: 5
  register: kubeadm_init
  when: inventory_hostname in groups['master']
- debug: msg={{ kubeadm_init }}
  when: print_debug == true and inventory_hostname in groups['master']
  # command: kubeadm init --control-plane-endpoint={{ hostvars[groups['master'][0]].ansible_hostname }}


- name: Set Fact for Token CA Certificate
  set_fact:
    k8s_token_ca_cert: "{{ (kubeadm_init.stdout_lines | select('search', 'discovery-token-ca-cert-hash') | list | string | split(' '))[1] }}"
  delegate_to: "{{ item }}"
  delegate_facts: True
  with_items: "{{ groups['all'] }}"
  when: inventory_hostname in groups['master']
- debug: msg={{ k8s_token_ca_cert }}
  when: print_debug == true and inventory_hostname in groups['master']


- name: Set Fact for Token
  set_fact:
    k8s_token: "{{ (kubeadm_init.stdout_lines | select('search', '--token') | list | string | split(' '))[4] }}"
  delegate_to: "{{ item }}"
  delegate_facts: True
  with_items: "{{ groups['all'] }}"
  when: inventory_hostname in groups['master']
- debug: msg={{ k8s_token }}
  when: print_debug == true and inventory_hostname in groups['master']


- name: Enable Your User to Start Using the Cluster.
  shell: |
    mkdir -p $HOME/.kube
    rm -f $HOME/.kube/config
    cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
    chown $(id -u):$(id -g) $HOME/.kube/config
  register: start_using_cluster_enabled
  when: inventory_hostname in groups['master']
- debug: msg={{ start_using_cluster_enabled }}
  when: print_debug == true and inventory_hostname in groups['master']


- name: Configure Kubectl Config
  shell: |
    kubectl taint nodes  {{ hostvars[groups['master'][0]].ansible_hostname }} node-role.kubernetes.io/control-plane:NoSchedule-
  register: kubectl_configured
  until: kubectl_configured is succeeded
  retries: 10
  delay: 10
  when: inventory_hostname in groups['master']
- debug: msg={{ kubectl_configured }}
  when: print_debug == true and inventory_hostname in groups['master']
  # kubectl taint nodes --all node-role.kubernetes.io/master-


- name: Confirm that the Kubectl Command is Activated.
  command: kubectl get nodes
  register: kubectl_get_nodes
  when: inventory_hostname in groups['master']
- debug: msg={{ kubectl_get_nodes }}
  when: print_debug == true and inventory_hostname in groups['master']


- name: Create POD for Master as well
  lineinfile:
    path: /root/.bashrc
    line: "{{ item.content }}"
    insertafter: EOF
    create: true
  register: master_pod_created
  with_items:
    - { content: " if [ -f /etc/bash_completion ] && ! shopt -oq posix; then " }
    - { content: "   . /etc/bash_completion " }
    - { content: " fi " }
    - { content: " source <(kubectl completion bash) " }
  when: inventory_hostname in groups['master']
- debug: msg={{ master_pod_created }}
  when: print_debug == true and inventory_hostname in groups['master']


# url: https://raw.githubusercontent.com/projectcalico/calico/v3.25.0/manifests/calico.yaml
- name: Download Calico Networking
  get_url:
    url: https://raw.githubusercontent.com/projectcalico/calico/v{{ calico.major_version}}.{{ calico.minor_version }}.{{ calico.patch_version }}/manifests/calico.yaml
    dest: /root/calico.yaml
    mode: 0644
  register: calico_downloaded
  when: inventory_hostname in groups['master']
- debug: msg={{ calico_downloaded }}
  when: print_debug == true and inventory_hostname in groups['master']
  # url: https://docs.projectcalico.org/manifests/calico.yaml
  # url: https://projectcalico.docs.tigera.io/manifests/calico.yaml


- name: Modify /root/calica.yaml for CIDR
  lineinfile:
    dest: /root/calico.yaml
    regexp: "{{ item.regexp }}"
    line: "{{ item.line }}"
    state: "{{ item.state }}"
    backrefs: "{{ item.backrefs }}"
  register: calico_cidr_modified
  with_items:
    - { regexp: "^            # - name: CALICO_IPV4POOL_CIDR", line: "            - name: CALICO_IPV4POOL_CIDR", state: present, backrefs: yes }
    - { regexp: "^            #   value: \"192.168.0.0/16\"", line: "              value: \"{{ calico.pod_network }}\"", state: present, backrefs: yes }
  when: inventory_hostname in groups['master']
- debug: msg={{ calico_cidr_modified }}
  when: print_debug == true and inventory_hostname in groups['master']


- name: Setup Networking with Calico
  command: kubectl apply -f /root/calico.yaml
  register: calico_network_setup
  when: inventory_hostname in groups['master']
- debug: msg={{ calico_network_setup }}
  when: print_debug == true and inventory_hostname in groups['master']


#- name: Setup Networking with Kube-Flannel
#  command: kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
#  register: kube_flannel_network_setup
#  when: inventory_hostname in groups['master']
#- debug: msg={{ kube_flannel_network_setup }}
#  when: print_debug == true and inventory_hostname in groups['master']


- name: Confirm that the Kubectl Command is Activated.
  command: kubectl get nodes
  register: kubectl_get_nodes
  when: inventory_hostname in groups['master']
- debug: msg={{ kubectl_get_nodes }}
  when: print_debug == true and inventory_hostname in groups['master']


# Initialize Workder Nodes in Kubernetes Cluster
- name: Reset Kubernetes on Cluster Nodes
  command:  kubeadm reset -f
  register: kube_cluster_reset
  when: inventory_hostname in groups['workers']
- debug: msg={{ kube_cluster_reset }}
  when: print_debug == true and inventory_hostname in groups['master']


- name: Join the Other Kubernetes Nodes to Cluster, the Command must be run on the Worker Nodes Only
  command: kubeadm join "{{ hostvars[groups['master'][0]]['ansible_'~netdev1]['ipv4']['address'] }}:6443" --token "{{ k8s_token }}" --discovery-token-ca-cert-hash "{{ k8s_token_ca_cert }}"
  register: store_it_copied
  ignore_errors: yes
  when: inventory_hostname in groups['workers']
- debug: msg={{ store_it_copied }}
  when: print_debug == true and inventory_hostname in groups['master']


- name: Confirm that the Kubectl Command is Activated
  command: kubectl get nodes
  register: kubectl_get_nodes
  when: inventory_hostname in groups['master']
- debug: msg={{ kubectl_get_nodes }}
  when: print_debug == true and inventory_hostname in groups['master']


- name: Enable and Start Kubelet in Master Node
  systemd:
    name: kubelet
    state: restarted
    enabled: yes
  register: master_kubelet_restarted
  when: inventory_hostname in groups['master']
- debug: msg={{ master_kubelet_restarted }}
  when: print_debug == true and inventory_hostname in groups['master']


- name: Validate if k8s Workers are all Ready
  shell: kubectl get nodes
  register: check_k8s_workers_status
  until: check_k8s_workers_status.stdout.find("NotReady") == -1
  retries: 30
  when: inventory_hostname in groups['master']
- debug: msg={{ check_k8s_workers_status }}
  when: print_debug == true and inventory_hostname in groups['master']


- name: Validate if All Containers are Running
  shell: kubectl get pods --all-namespaces -o wide
  register: all_containers_running_checked
  until: all_containers_running_checked.stdout.find("ContainerCreating") == -1
  retries: 30
  when: inventory_hostname in groups['master']
- debug: msg={{ all_containers_running_checked }}
  when: print_debug == true and inventory_hostname in groups['master']


# erinformations/default": x509: certificate signed by unknown authority 
# (possibly because of "crypto/rsa: verification error" while trying to verify candidate authority certificate

# docker login --username="rokmc756@gmail.com"
# kubectl apply -f nginx-deploy.yml

# kubectl patch svc nginx -p '{"spec":{"externalIPs":["192.168.1.194"]}}'
# kubectl get all
# ~~ snip
# service/nginx        NodePort    10.96.0.2    192.168.1.194   80:30001/TCP   2m30s

# kubectl port-forward service/nginx 80:80

# kubectl expose deployment hello-world --type=LoadBalancer --name=nginx --external-ip=192.168.0.194

# kubectl expose deployment nginx --type=NodePort

# kubectl expose deployment nginx --type=LoadBalancer --name=nginx-access

# https://coredns.io/manual/installation/

# https://kubernetes.io/docs/tutorials/services/connect-applications-service/

# https://coredns.io/manual/installation/

# https://coredns.io/2018/01/29/deploying-kubernetes-with-coredns-using-kubeadm/#understanding-coredns-configuration
# https://coredns.io/2018/01/29/deploying-kubernetes-with-coredns-using-kubeadm/#understanding-coredns-configuration
# https://github.com/projectcalico/calico/issues/2695
# https://tech.kakao.com/2021/03/03/network-node-manager/
# https://deploy.live/blog/kubernetes-networking-problems-due-to-the-conntrack/
#

